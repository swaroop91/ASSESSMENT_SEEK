from urllib import request
url = 'https://www.kaggle.com/madhab/jobposts/downloads/data%20job%20posts.csv/1'
def download_data(csv_url):
	response = request.urlopen(csv_url)
	csv = response.read()
	csv_str = str(csv)
	lines = csv_str.split("\\n")
	dest_url = r'F:\data job posts.csv'
	fx = open(dest_url, "w")
	for line in lines:
		fx.write(line + "\n")
	fx.close()
download_data(url)

import pandsd as pd
salesdf = pd.read_csv("F:\Sales_Transactions_Dataset_Weekly.csv")
import numpy as np

b.
fields = ["Title",'Duration','Location','JobDescription','JobRequirment','RequiredQual','Salary','Deadline','AboutC']
jobpostdf = pd.read_csv("F:\data job posts.csv",usecols=fields)

c.
fields = ["Title",'Duration','Location','JobDescription','JobRequirment','RequiredQual','Salary','Deadline','AboutC','Company','date']
jobpostdf = pd.read_csv("F:\data job posts.csv",usecols=fields)
jobpostadsdf=jobpostdf.groupby(['Company']).size().reset_index(name='Counts').sort_values(by='Counts',ascending=False).iloc[0:1]

e.
import nltk
stopwords = nltk.corpus.stopwords.words('english')
RE_stopwords = r'\b(?:{})\b'.format('|'.join(stopwords))
# replace '|'-->' ' and drop all stopwords
words = (jobpostdf.JobRequirment
           .str.lower()
           .replace([r'\|', RE_stopwords], [' ', ''], regex=True)
)
jobpostdf.JobRequirment=words

jobpostdf.Duration=jobpostdf.Duration.fillna("Duration value is NA")


f.
jobpostdf.Duration.fillna("Duration value is NA")
